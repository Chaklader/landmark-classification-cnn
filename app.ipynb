{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662ba368",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for Landmark Classification\n",
    "\n",
    "### A simple app\n",
    "\n",
    "In this notebook we build a very simple app that uses our exported model.\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Note how we are not importing anything from our source code (we do not use any module from the ``src`` directory). This is because the exported model, differently from the model weights, is a standalone serialization of our model and therefore it does not need anything else. You can ship that file to anybody, and as long as they can import ``torch``, they will be able to use your model. This is very important for releasing pytorch models to production.\n",
    "\n",
    "### Test your app\n",
    "Go to a search engine for images (like Google Images) and search for images of some of the landmarks, like the Eiffel Tower, the Golden Gate Bridge, Machu Picchu and so on. Save a few examples locally, then upload them to your app to see how your model behaves!\n",
    "\n",
    "The app will show the top 5 classes that the model think are most relevant for the picture you have uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda5a833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:41:30.990811Z",
     "start_time": "2024-10-25T10:41:30.904979Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/udacity/lib/python3.8/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/miniconda3/envs/udacity/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <CAF361F5-1CAC-3EBE-9FC4-4B823D275CAA> /opt/miniconda3/envs/udacity/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/miniconda3/envs/udacity/lib/python3.8/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/udacity/lib/python3.8/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/udacity/lib/python3.8/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/udacity/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully!\n",
      "Setting up click handler...\n",
      "Click handler set up!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a404d1fb5ab34d00b440c7510b5a0dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Please upload a picture of a landmark'), FileUpload(value=(), description='Upload'â€¦"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "print(\"Loading model...\")\n",
    "learn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "def on_click_classify(change):\n",
    "    try:\n",
    "        print(\"Button clicked!\")\n",
    "        \n",
    "        if not btn_upload.value:\n",
    "            print(\"No files uploaded yet!\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Number of files uploaded: {len(btn_upload.value)}\")\n",
    "        print(\"Starting classification...\")\n",
    "        \n",
    "        print(\"Loading image...\")\n",
    "        fn = io.BytesIO(btn_upload.value[-1]['content'])  \n",
    "\n",
    "        img = Image.open(fn)\n",
    "        img.load()\n",
    "        print(\"Image loaded successfully!\")\n",
    "\n",
    "        out_pl.clear_output()\n",
    "\n",
    "        print(\"Displaying image...\")\n",
    "        with out_pl:\n",
    "            ratio = img.size[0] / img.size[1]\n",
    "            c = img.copy()\n",
    "            c.thumbnail([ratio * 200, 200])\n",
    "            display(c)\n",
    "        print(\"Image displayed!\")\n",
    "\n",
    "        print(\"Converting to tensor...\")\n",
    "        timg = T.ToTensor()(img).unsqueeze_(0)\n",
    "        print(f\"Tensor shape: {timg.shape}\")\n",
    "\n",
    "        print(\"Running inference...\")\n",
    "        softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n",
    "        print(\"Inference complete!\")\n",
    "        \n",
    "        print(\"Processing results...\")\n",
    "        idxs = np.argsort(softmax)[::-1]\n",
    "        \n",
    "        for i in range(5):\n",
    "            p = softmax[idxs[i]]\n",
    "            landmark_name = learn_inf.class_names[idxs[i]]\n",
    "            labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n",
    "        print(\"Classification complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "btn_upload = FileUpload()\n",
    "btn_run = Button(description=\"Classify\")\n",
    "print(\"Setting up click handler...\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "print(\"Click handler set up!\")\n",
    "\n",
    "labels = []\n",
    "for _ in range(5):\n",
    "    labels.append(Label())\n",
    "\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "VBox(wgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f9867",
   "metadata": {},
   "source": [
    "## (optional) Standalone app or web app\n",
    "\n",
    "You can run this notebook as a standalone app on your computer by following these steps:\n",
    "\n",
    "1. Download this notebook in a directory on your machine\n",
    "2. Download the model export (for example, ``checkpoints/transfer_exported.pt``) in a subdirectory called ``checkpoints`` within the directory where you save the app.ipynb notebook\n",
    "3. Install voila if you don't have it already (``pip install voila``)\n",
    "4. Run your app: ``voila app.ipynb --show_tracebacks=True``\n",
    "5. Customize your notebook to make your app prettier and rerun voila\n",
    "\n",
    "You can also deploy this app as a website using Binder: https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87207e",
   "metadata": {},
   "source": [
    "# Create your submission archive\n",
    "\n",
    "Now that you are done with your project, please run the following cell. It will generate a file containing all the code you have written, as well as the notebooks. Please submit that file to complete your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbba984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook app.ipynb to html\n",
      "[NbConvertApp] Writing 291944 bytes to app.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html app.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5948d9a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:15:03.195544Z",
     "start_time": "2024-10-25T12:14:59.640453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing: jupyter nbconvert --to html transfer_learning.ipynb\r\n",
      "[NbConvertApp] Converting notebook transfer_learning.ipynb to html\r\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 2 image(s).\r\n",
      "[NbConvertApp] Writing 538705 bytes to transfer_learning.html\r\n",
      "executing: jupyter nbconvert --to html app.ipynb\r\n",
      "[NbConvertApp] Converting notebook app.ipynb to html\r\n",
      "[NbConvertApp] Writing 291944 bytes to app.html\r\n",
      "executing: jupyter nbconvert --to html cnn_from_scratch.ipynb\r\n",
      "[NbConvertApp] Converting notebook cnn_from_scratch.ipynb to html\r\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 3 image(s).\r\n",
      "[NbConvertApp] Writing 1764831 bytes to cnn_from_scratch.html\r\n",
      "Adding files to submission_2024-10-25T18h15m.tar.gz\r\n",
      "src/predictor.py\r\n",
      "src/create_submit_pkg.py\r\n",
      "src/optimization.py\r\n",
      "src/__init__.py\r\n",
      "src/model.py\r\n",
      "src/transfer.py\r\n",
      "src/train.py\r\n",
      "src/helpers.py\r\n",
      "src/data.py\r\n",
      "transfer_learning.ipynb\r\n",
      "app.ipynb\r\n",
      "cnn_from_scratch.ipynb\r\n",
      "transfer_learning.html\r\n",
      "cnn_from_scratch.html\r\n",
      "app.html\r\n",
      "\r\n",
      "----------------------------------------------------------------\r\n",
      "Done. Please submit the file submission_2024-10-25T18h15m.tar.gz\r\n",
      "----------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!python src/create_submit_pkg.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (udacity)",
   "language": "python",
   "name": "udacity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
