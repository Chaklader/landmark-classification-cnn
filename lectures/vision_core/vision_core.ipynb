{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e165a8",
   "metadata": {},
   "source": [
    "This codebase can be used for many purposes including:\n",
    "\n",
    "1. **Object Detection Pipeline**:\n",
    "- Train/evaluate models (Faster R-CNN, Mask R-CNN, etc)\n",
    "- Process COCO-format datasets\n",
    "- Calculate evaluation metrics (mAP, IoU)\n",
    "\n",
    "2. **Key Components Available:**\n",
    "\n",
    "Data Preparation:\n",
    "- Image transforms/normalization\n",
    "- Annotation processing\n",
    "- Dataset utilities\n",
    "\n",
    "Training Infrastructure:\n",
    "- Distributed training setup\n",
    "- Learning rate scheduling\n",
    "- Loss tracking\n",
    "\n",
    "Evaluation Tools:\n",
    "- COCO metric calculation\n",
    "- Prediction visualization\n",
    "- Model performance analysis\n",
    "\n",
    "3. **Experiment Ideas:**\n",
    "- Transfer Learning:\n",
    "- Fine-tune pretrained models on custom data\n",
    "- Modify head architectures\n",
    "- Data Augmentation:\n",
    "- Test different transform combinations\n",
    "- Visualize augmented samples\n",
    "\n",
    "4. **Performance Optimization:**\n",
    "- Benchmark training speed\n",
    "- Profile memory usage\n",
    "- Test mixed-precision\n",
    "\n",
    "5. **Visualization Capabilities:**\n",
    "- Plot training metrics\n",
    "- Visualize predictions vs ground truth\n",
    "- Generate confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494646b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Starting training for 5 epochs...\n"
     ]
    }
   ],
   "source": [
    "# In vision_core.ipynb\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import sys\n",
    "import math # <<<<------ ADDED IMPORT MATH\n",
    "\n",
    "# ------------------- PATH SETUP -------------------\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\" if \"__file__\" in locals() else os.getcwd()))\n",
    "# Assuming 'vision_core' is a subdirectory within 'lectures'\n",
    "# and the notebook is also in 'lectures/vision_core/'\n",
    "# So we need to go up one level from notebook_dir to get to 'lectures'\n",
    "# then 'vision_core' can be imported.\n",
    "parent_dir_of_package_root = os.path.dirname(notebook_dir) # This should be 'lectures'\n",
    "if parent_dir_of_package_root not in sys.path:\n",
    "    sys.path.append(parent_dir_of_package_root)\n",
    "\n",
    "from vision_core import utils, engine\n",
    "\n",
    "# ------------------- DEBUG ANOMALY (Optional) -------------------\n",
    "# Uncomment the next line for detailed error messages when NaNs first appear.\n",
    "# This will slow down training, so use it only for debugging.\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# ------------------- DEVICE SETUP -------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------- CUSTOM COLLATE FUNCTION FOR DETECTION -------------------\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# ------------------- MOCK DATASET (Improved Box Generation) -------------------\n",
    "class FakeDataset(Dataset):\n",
    "    def __init__(self, num_samples=100, image_size=(3, 300, 400)):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.img_height = image_size[1]\n",
    "        self.img_width = image_size[2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.rand(self.image_size)\n",
    "        num_boxes = torch.randint(1, 6, (1,)).item() # 1 to 5 boxes\n",
    "\n",
    "        boxes_list = []\n",
    "        labels_list = []\n",
    "\n",
    "        for _ in range(num_boxes):\n",
    "            min_box_dim = 10 \n",
    "            x1 = torch.rand(1).item() * (self.img_width - min_box_dim - 1) \n",
    "            y1 = torch.rand(1).item() * (self.img_height - min_box_dim - 1)\n",
    "            \n",
    "            width = torch.rand(1).item() * (self.img_width - x1 - min_box_dim) + min_box_dim\n",
    "            height = torch.rand(1).item() * (self.img_height - y1 - min_box_dim) + min_box_dim\n",
    "            \n",
    "            x2 = x1 + width\n",
    "            y2 = y1 + height\n",
    "\n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(self.img_width -1 , x2) # -1 to keep it strictly within bounds for some ops\n",
    "            y2 = min(self.img_height -1, y2)\n",
    "\n",
    "            if x2 <= x1: x2 = x1 + min_box_dim / 2 if x1 + min_box_dim/2 < self.img_width else self.img_width -1\n",
    "            if y2 <= y1: y2 = y1 + min_box_dim / 2 if y1 + min_box_dim/2 < self.img_height else self.img_height -1\n",
    "            if x2 <= x1 : x1 = x2 - min_box_dim /2 if x2 - min_box_dim/2 > 0 else 0\n",
    "            if y2 <= y1 : y1 = y2 - min_box_dim /2 if y2 - min_box_dim/2 > 0 else 0\n",
    "            \n",
    "            # Final check to ensure box is valid\n",
    "            if x1 >= x2: x1 = x2 - 1\n",
    "            if y1 >= y2: y1 = y2 - 1\n",
    "            if x1 < 0: x1 = 0\n",
    "            if y1 < 0: y1 = 0\n",
    "\n",
    "\n",
    "            boxes_list.append([x1, y1, x2, y2])\n",
    "            labels_list.append(torch.randint(1, 91, (1,)).item())\n",
    "\n",
    "        if not boxes_list: \n",
    "            boxes_list.append([10, 10, 50, 50])\n",
    "            labels_list.append(1)\n",
    "            \n",
    "        boxes_tensor = torch.tensor(boxes_list, dtype=torch.float32)\n",
    "        # Ensure no zero area boxes if any slipped through\n",
    "        valid_areas = (boxes_tensor[:, 2] - boxes_tensor[:, 0]) * (boxes_tensor[:, 3] - boxes_tensor[:, 1]) > 0\n",
    "        if not torch.all(valid_areas):\n",
    "             # If any invalid, just create a single valid box\n",
    "             boxes_tensor = torch.tensor([[10.0, 10.0, 50.0, 50.0]], dtype=torch.float32)\n",
    "             labels_tensor = torch.tensor([1], dtype=torch.int64)\n",
    "        else:\n",
    "            labels_tensor = torch.tensor(labels_list, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes_tensor\n",
    "        target[\"labels\"] = labels_tensor\n",
    "        target[\"image_id\"] = torch.tensor([idx], dtype=torch.int64)\n",
    "        target[\"area\"] = (target[\"boxes\"][:, 3] - target[\"boxes\"][:, 1]) * \\\n",
    "                         (target[\"boxes\"][:, 2] - target[\"boxes\"][:, 0])\n",
    "        target[\"iscrowd\"] = torch.zeros((boxes_tensor.shape[0],), dtype=torch.uint8)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def get_coco_api(self):\n",
    "        from pycocotools.coco import COCO\n",
    "        mock_coco = COCO()\n",
    "        mock_coco.dataset = {'images': [{'id': i} for i in range(self.num_samples)], 'annotations': []}\n",
    "        mock_coco.createIndex()\n",
    "        return mock_coco\n",
    "\n",
    "# ------------------- MODEL AND OPTIMIZER -------------------\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True, num_classes=91)\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005) # Further reduced LR\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# ------------------- DATA LOADERS -------------------\n",
    "train_dataset = FakeDataset(num_samples=200) \n",
    "val_dataset = FakeDataset(num_samples=50)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=2, shuffle=True, num_workers=0, collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# ------------------- TRAINING AND VALIDATION LOOP (WITH GRADIENT CLIPPING) -------------------\n",
    "num_epochs = 5 \n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    current_lr_scheduler = None\n",
    "    if epoch == 0: # Warmup for the first epoch only\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(train_loader) - 1)\n",
    "        current_lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "    \n",
    "    for i, (images, targets) in enumerate(metric_logger.log_every(train_loader, 10, header)): \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value): # <<<<------ CORRECTED LINE\n",
    "            print(f\"Loss is {loss_value} at epoch {epoch}, iteration {i}, stopping training\")\n",
    "            print(loss_dict_reduced)\n",
    "            # Optionally, save the problematic batch for inspection\n",
    "            # torch.save({'images': images, 'targets': targets}, 'problem_batch.pth')\n",
    "            sys.exit(1) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) \n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if current_lr_scheduler is not None:\n",
    "            current_lr_scheduler.step()\n",
    "\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "    \n",
    "    if lr_scheduler is not None and epoch > 0: # Main LR scheduler steps after warmup phase (epoch 0)\n",
    "         lr_scheduler.step()\n",
    "    \n",
    "    engine.evaluate(model, val_loader, device=device)\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of making a prediction (after training)\n",
    "model.eval()\n",
    "sample_image, _ = val_dataset[0]\n",
    "with torch.no_grad():\n",
    "    prediction = model([sample_image.to(device)])\n",
    "print(\"\\nExample prediction:\")\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
