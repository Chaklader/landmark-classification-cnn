# C-5: Autoencoders

<br>
<br>

#### Autoencoder Fundamentals

Autoencoders represent a specialized neural network architecture that learns to encode data into a compressed
representation and then decode it back to the original form. Unlike standard neural networks for classification or
regression, autoencoders are trained to reconstruct their own inputs, creating a powerful framework for unsupervised
learning and representation discovery.

##### Core Architecture Components

The autoencoder architecture consists of three fundamental components that work together to compress and reconstruct
data:

###### Encoder

The encoder transforms the high-dimensional input data into a lower-dimensional representation. For images, this
typically involves progressively reducing spatial dimensions while extracting meaningful features. The encoder can be
thought of as a function $f$ that maps an input $x$ to a latent representation $z$:

$$z = f(x)$$

In practice, the encoder often resembles the backbone of classification networks—convolutional layers for images or
dense layers for vectorized data—but critically, it terminates in a bottleneck layer rather than classification outputs.

###### Latent Representation (Embedding)

The compressed information produced by the encoder, often called the embedding or latent representation, forms the
bottleneck of the autoencoder. This representation captures the essential features of the input in a much smaller
dimensional space. The dimensionality of this space significantly influences what the autoencoder learns:

- Very small embeddings force the network to learn only the most essential features
- Larger embeddings allow more detail to be preserved but risk memorizing rather than generalizing

This latent space can be analyzed to understand data structure, identify clusters, or generate new samples by
interpolating between existing points.

###### Decoder

The decoder attempts to reconstruct the original input from the compressed latent representation. It performs the
inverse mapping of the encoder, progressively expanding the latent representation back to the original input dimensions.
Mathematically, the decoder implements a function $g$ that maps the latent representation $z$ back to a reconstruction
$\hat{x}$:

$$\hat{x} = g(z)$$

The decoder architecture typically mirrors the encoder in reverse, with upsampling operations replacing downsampling
ones.

##### Unsupervised Learning Paradigm

A defining characteristic of autoencoders is their self-supervised nature—they learn meaningful representations without
requiring labeled data. This makes them particularly valuable when labeled data is scarce or expensive to obtain.

###### Self-Supervised Training Signal

The training signal for autoencoders comes from comparing the network's output to its own input. The network learns to
identify and preserve the most important features of the data by attempting to recreate the input from a compressed
representation. This self-supervision distinguishes autoencoders from traditional supervised approaches:

- Supervised learning: Learns mappings from inputs to predefined labels
- Unsupervised autoencoder learning: Learns mappings from inputs back to those same inputs through a constrained
  bottleneck

###### Information Prioritization

The bottleneck in the architecture forces the network to prioritize which aspects of the input data are most important
to preserve. This constraint drives the discovery of efficient representations that capture the underlying structure and
patterns in the data.

Through this process, autoencoders often learn semantically meaningful features without explicit guidance—separating
digits by their natural visual similarities in handwritten digit datasets, for example, despite never being told which
images belong to which digit classes.

##### Loss Functions for Reconstruction

The training objective for autoencoders involves minimizing the difference between the original input and its
reconstruction. Several loss functions can serve this purpose, with Mean Squared Error (MSE) being the most common.

###### Mean Squared Error

MSE measures the average squared difference between corresponding elements in the input and reconstruction. For image
data with dimensions $n_{\text{rows}} \times n_{\text{cols}}$, the MSE is calculated as:

$$\text{MSE} = \frac{1}{n_{\text{rows}}n_{\text{cols}}} \sum_{i=1}^{n_{\text{rows}}} \sum_{j=1}^{n_{\text{cols}}} (x_{ij} - \hat{x}_{ij})^2$$

Where:

- $x_{ij}$ represents the pixel value at position $(i,j)$ in the original image
- $\hat{x}_{ij}$ represents the corresponding pixel in the reconstructed image

This loss function encourages the network to minimize the average pixel-wise error across the entire image, treating
each pixel position as equally important.

###### Alternative Loss Functions

While MSE is most common, other loss functions may be more appropriate depending on the data and application:

- Binary Cross-Entropy: Often used when input values are binary or normalized between 0 and 1
- L1 Loss (Mean Absolute Error): Less sensitive to outliers than MSE, sometimes preferred for robust training
- Perceptual Losses: Based on feature activations in pretrained networks, better aligned with human perception for image
  data

The choice of loss function significantly impacts what features the autoencoder prioritizes during reconstruction,
ultimately determining what kind of information is preserved in the latent space.

##### Balancing Reconstruction and Compression

The fundamental tension in autoencoder design lies in balancing reconstruction quality against meaningful compression. A
perfect reconstruction might simply memorize the training data without learning useful representations, while excessive
compression might lose important information.

This balance is controlled through:

1. The dimensionality of the latent space
2. The capacity of the encoder and decoder networks
3. Additional regularization techniques that encourage useful properties in the latent space

Finding the right balance allows autoencoders to discover representations that capture the underlying data manifold
rather than memorizing individual examples—a critical distinction that enables their use in anomaly detection,
denoising, and generative modeling applications.

By understanding these fundamental aspects of autoencoders, we lay the groundwork for exploring more sophisticated
variants and applications, from convolutional architectures to variational formulations that enable true generative
modeling.

Autoencoders are a very interesting neural network architecture that can be used for different applications directly (
anomaly detection, denoising, ...), and it is also widely used in larger and modern architectures for other tasks (
object detection, image segmentation). More advanced versions of autoencoders, such as variational autoencoders, can
also be used as generative models, i.e., they can learn representations of data and use that representation to generate
new realistic images. In this lesson, you will learn:

1. About linear and CNN-based autoencoders
2. How to design and train a linear autoencoder for anomaly detection
3. How to design and train a CNN autoencoder for anomaly detection
4. How to apply autoencoders for image denoising
5. About autoencoders and generative models

When studying CNNs for image classification or regression we have seen that the network is essentially composed of two
parts:

1. A backbone that extracts features from the image

2. Multi-Layer Perceptron or similar that uses those features to decide which class the image belongs to. In-between the
   two we have a flattening operation (or a Global Average Pooling layer) that takes the last feature maps coming out of
   the backbone and transforms them into a 1d array, which is a feature vector.

Autoencoders have a similar backbone (called encoder in this context) that produces a feature vector (called embedding
in this context). However, they substitute the fully-connected layers (the head) with a decoder stage whose scope is to
reconstruct the input image starting from the embeddings:

This can appear pointless at first glance, but it is actually very useful in many contexts. We can use autoencoders to:

1. Compress data
2. Denoise data
3. Find outliers (do anomaly detection) in a dataset
4. Do inpainting (i.e., reconstruct missing areas of an image or a vector)
5. With some modifications, we can use autoencoders as generative models - models capable of generating new images

Autoencoders are also the basis for a whole field of research concerned with metric learning, which is learning
representations of images that can be useful in downstream tasks.

By looking closer at the structure and the tasks we have just described, you can see that autoencoders do not use the
information on the label of the image at all. They are only concerned with the image itself, not with its label. The
tasks that autoencoders address are examples of _unsupervised learning_, where the algorithm can learn from a dataset
without any label. Another example of _unsupervised learning_ that you might be familiar with is clustering. CNNs for
image classification are instead an example of supervised learning, where the network learns to distinguish between
classes by learning from a labeled dataset.

The autoencoder is concerned with encoding the input to a compressed representation, and then re-constructing the
original image from the compressed representation. The signal to train the network comes from the differences between
the input and the output of the autoencoder. For example, let's consider an autoencoder for images. We compare the input
image to the output image, and we want them to be as similar as possible.

To find the right loss for this task, we have different possibilities, but the most common one is the _Mean Squared
Error_ _(MSE)_ loss. It just considers the square of the difference between each pixel in the input image and the
corresponding pixel in the output image, so minimizing this loss is equivalent to minimizing the difference of each
pixel in the input with the corresponding pixel in the output. In practice, this is given by the formula:

$MSE = \frac{1}{n_{\text{rows}}n_{\text{cols}}} \sum_{i=1}^{n_{\text{rows}}} \sum_{j=1}^{n_{\text{cols}}} (x_{ij} -
\hat{x}_{ij})^2$

Where:

- $n_{\text{rows}}$ is the number of rows in the image
- $n_{\text{cols}}$ is the number of columns in the image
- $x_{ij}$ is the pixel value at position (i,j) in the input image
- $\hat{x}_{ij}$ is the pixel value at position (i,j) in the output image
- $\sum_{i=1}^{n_{\text{rows}}} \sum_{j=1}^{n_{\text{cols}}}$ represents summation over all pixels

<br>

The MSE loss provides a measure of the average squared difference between corresponding pixels in the input and
reconstructed images, commonly used in image-related tasks like autoencoders and image generation. In this first look we
have built the simplest autoencoder, which is made up of two linear layers:

<br>
<br>

```python
class Autoencoder(nn.Module):

    def __init__(self, encoding_dim):
        super(Autoencoder, self).__init__()
        ## encoder ##
        self.encoder = nn.Sequential(
            nn.Linear(28*28, encoding_dim),
            nn.ReLU(),
            nn.BatchNorm1d(encoding_dim)
        )

        ## decoder ##
        self.decoder = nn.Sequential(
            nn.Linear(encoding_dim, 28*28),
            nn.Sigmoid()
        )

        self.auto_encoder = nn.Sequential(
            nn.Flatten(),
            self.encoder,
            self.decoder
        )

    def forward(self, x):
        # define feedforward behavior
        # and scale the *output* layer with a sigmoid activation function

        encoded = self.auto_encoder(x)

        # Reshape the output as an image
        # remember that the shape should be (batch_size, channel_count, height, width)
        return encoded.reshape((x.shape[0], 1, 28, 28))
```

<br>
<br>

We have trained it using the Mean Squared Error (MSE) loss. Of course, we did not use the labels, since anomaly
detection with autoencoders is an unsupervised task.

We have seen how to use linear layers to create an autoencoder. Since we are working on images, it is natural to use
convolution instead of just linear layers. Convolution allows us to keep spatial information and get a much more
powerful representation of the content of an image.

However, this poses a problem: while the encoder section can be just the backbone of a standard CNN, what about the
decoder part? Yes, we could flatten the output of the backbone and then use linear layers to decode. But there are other
ways to sample a compact representation into a full-resolution image. For example, we can use a Transposed Convolutional
Layer, which can learn how to best upsample an image. We'll see how that works on the next page.

<br>
<br>

#### Learnable Sampling

We have seen how to use linear layers to create an autoencoder. Since we are working on images, it is natural to use
convolution instead of just linear layers. Convolution allows us to keep spatial information and get a much more
powerful representation of the content of an image.

However, this poses a problem: while the encoder section can be just the backbone of a standard CNN, what about the
decoder part? Yes, we could flatten the output of the backbone and then use linear layers to decode. But there are other
ways to sample a compact representation into a full-resolution image. For example, we can use a Transposed Convolutional
Layer, which can learn how to best sample an image. We'll see how that works on the next page.

<br>
<br>

#### Transposed Convolutions

The Transposed Convolution can perform an upsampling of the input with learned weights. In particular, a Transposed
Convolution with a 2 x 2 filter and a stride of 2 will double the size of the input image.

Whereas a Max Pooling operation with a 2 x 2 window and a stride of 2 reduces the input size by half, a Transposed
Convolution with a 2 x 2 filter and a stride of 2 will double the input size.

Let's consider an autoencoder with two Max Pooling layers in the encoder, both having a 2 x 2 window and a stride of 2.
If we want the network to output an image with the same size as the input, we need to counteract the two Max Pooling
layers in the encoder with two Transposed Convolution layers with a 2 x 2 filter and a stride of 2 in the decoder. This
will give us back an output with the same size as the input. We can generate a Transposed Convolution Layer in PyTorch
with:

```python
unpool = nn.ConvTranspose2d(input_ch, output_ch, kernel_size, stride=2)
```

For example, we can generate a Transposed Convolution Layer that doubles the size of an input grayscale image and
generates 16 feature maps as follows:

```python
unpool = nn.ConvTranspose2d(1, 16, 2, stride=2)
```

The Transposed Convolutions tend to produce checkerboard artifacts in the output of the networks as detailed in the
Distill article. Therefore, nowadays, many practitioners replace them with a _nearest-neighbor upsampling_ operation
followed by a convolution operation. The convolution makes the image produced by the nearest-neighbors smoother. For
example, we can replace this Transposed Convolution:

```python
unpool = nn.ConvTranspose2d(1, 16, 2, stride=2)
```

with:

```python
unpool = nn.Sequential(
    nn.Upsample(scale_factor = 2, mode='nearest'),
    nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
)
```

The simplest autoencoder using CNNs can be constructed with a convolutional layer followed by Max Pooling, and then an
unpooling operation (such as a Transposed Convolution) that brings the image back to its original size:

```python
class Autoencoder(nn.Module):
    def __init__(self, encoding_dim):
        super(Autoencoder, self).__init__()

        ## encoder ##
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 3, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )

        ## decoder ##
        self.decoder = nn.Sequential(
            # Undo the Max Pooling
            nn.ConvTranspose2d(3, 1, 2, stride=2),
            nn.Sigmoid()
        )

        self.auto_encoder = nn.Sequential(
            self.encoder,
            self.decoder
        )

    def forward(self, x):
        # define feedforward behavior
        # and scale the *output* layer with a sigmoid activation function

        return self.auto_encoder(x)
```

Of course, this autoencoder is not very performant. Typically you want to compress the information much more with a
deeper encoder, and then uncompress it with a deeper decoder. This is what you are going to do in the next exercise.

In real-life situations, you can also use an already-existing architecture like a ResNet to extract the features (just
remember to remove the final linear layers, i.e., the head and only keep the backbone). Of course, your decoder needs to
then start from the embedding built by the architecture to get back to the dimension of the input image.

#### Denoising

We call denoising the task of removing noise from an image by reconstructing a denoised image. This is a task that
convolutional autoencoders are well-suited for.

<p align="center">
<img src="images/denoise.png" alt="Denoising Autoencoder" width="600" height=auto>
</p>
<p align="center">figure: Denoising Autoencoder architecture showing the process of noise removal</p>

<br>
<br>

In order to train a denoising autoencoder we need to have access to the denoised version of the images. The easiest way
to do this is to build a training dataset by taking clean images and adding noise to them. Then we will feed the image
with the added noise into the autoencoder, and ask it to reconstruct the denoised (original) version.

It is very important that we then compute the loss by comparing the input uncorrupted image (without noise) and the
output of the network. DO NOT use the noisy version when computing the loss, otherwise your network will not learn!

Let's consider an autoencoder trained on a noisy version of the MNIST dataset. During training, the autoencoder sees
many examples of all the numbers. Each number has noisy pixels in different places. Hence, even though each number is
corrupted by noise, the autoencoder can piece together a good representation for each number by learning different
pieces from different examples. Here the convolutional structure helps a lot, because after a few layers the convolution
smooths out a lot of the noise in a blurry but useful image of the number. This is also why generally you need to go
quite deep with CNN autoencoders if you want to use them for denoising.

#### Questions and Answers

##### Q#1: If the tensor `images` represents a batch of uncorrupted images, and `noisy_images` represents a batch

of images where we added noise, which is the correct application of the loss? (Assume that `outputs` is a batch of
outputs from the autoencoder, and `loss = nn.MSELoss()`.)

Answer: `loss(images, outputs)`. You have to compare the output of the network with the uncorrupted images.

Explanation: In a denoising autoencoder:

1. The input is the noisy image (`noisy_images`)
2. The output is the network's attempt to reconstruct the clean image
3. We want to compare this reconstruction (`outputs`) with the original clean images (`images`)
4. Therefore, we calculate loss between the network's output and the original clean images

The goal is to train the network to remove noise, so we compare its output to the original clean image, not to the noisy
input or any other combination.

##### Q#2: What are the operations that are involved in training a denoising autoencoder? (check all that apply)

Answer: All options apply:

1. Loop over each batch in the training data loader
2. Add noise to the images in the batch
3. Compute the prediction from the network, i.e., the reconstructed images
4. Compare the reconstructed images with the input (uncorrupted) images using a loss like nn.MSELoss
5. Perform backpropagation

Explanation: The training process for a denoising autoencoder involves all these steps in sequence:

1. First, we need to iterate through our training data in batches
2. For each batch, we create a noisy version of the images (this is what makes it a "denoising" autoencoder)
3. We pass the noisy images through the network to get reconstructed images
4. We compare these reconstructions with the original clean images using MSE loss
5. Finally, we use backpropagation to update the network's weights to minimize this loss

This complete process allows the autoencoder to learn how to remove noise from images by trying to reconstruct clean
versions from noisy inputs. As we have seen, an autoencoder has an encoder part that compresses the input into a vector
(embedding) and a decoder part that takes the embedding and tries to regenerate the input.

Let's look closer at the embeddings for the MNIST dataset. Even though we did not use the labels for training the
autoencoder, we can use them for visualization purposes and see if the embedding that the encoder has learned separates
well the various classes. After all, if the encoder has learned the latent characteristics that distinguish a 3 from a 1
or a 8 from a 7, then the embedding space should reflect this structure.

Let's consider the CNN autoencoder we presented as a solution to the Convolutional Encoder exercise of this lesson. It
has a latent space (where the embeddings live) of 32 feature maps each 7 x 7 pixels. This corresponds to 1568 numbers.
Of course we cannot visualize a space with 1568 dimensions, so we are going to use the UMAP dimensionality reduction
technique to visualize it in 2d:

Here the different colors correspond to the different classes in the MNIST dataset (the different digits). To make
things easier, I annotated each cluster with the label of the most common class in the cluster.

It is indeed clear that images representing similar numbers are clustered together. Not only are most of the points
belonging to the same class close to each other, but also numbers that are visually similar to each other (like 3, 8
and 5. are close in the latent space.

Looking at this we could ask: what happens if we generate an embedding vector close to one of these clusters, and run it
through the decoder? We should be able to generate new numbers! This is indeed the case. If we take a few points in the
embedding space and run them through the decoder, we obtain images.

However, if we repeat this exercise enough we soon realize that things don't look so great. The embedding space of an
autoencoder is discontinuous: you can take an embedding of a 3, modify it just a tiny bit and end up with a completely
different number, or even something that does not resemble a number at all. Why? Because in our training we use a loss
that does not enforce any particular structure in the embedding space, so the network finds the one that happens to
solve our problem best, without considering any constraints regarding the structure of the space.

In more formal terms we can say that the autoencoder learns a mapping between our images and the embedding space. It
does not learn the distribution of the data in the embedding space.

This problem can be solved by other algorithms, for example the so-called Variational Autoencoders (VAEs). They learn to
project our points in an embedding space that has much more structure than a simple autoencoder. VAEs are proper
generative models, in that they learn to represent the distribution of the dataset and therefore their embedding space
is much more regular and more suited for data generation. A deeper dive into VAEs goes beyond the scope of this class,
but you can find more information here. With what you learned in this lesson you should be able to learn VAEs in a
breeze!
